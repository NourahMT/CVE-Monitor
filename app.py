#!/user/bin/env python3
"""
This tool built to keep track CVE list provided by NVD, and display the list in a table format
the tool creates a new thread every (x) seconds to request last modified meta date
and check if there's an update since last request.
"""
__author__ = "Nourah Altawallah"
__copyright__ = "Copyright 2019"
__license__ = "GPL"
__version__ = "1.0.5"
__date__ = "2019-10-09"
__maintainer__ = "Fahad Alduraibi"
__email__ = "fahad@fadvisor.net"


import datetime
import json
import random
import time
import flashtext 
import gzip
import json
import threading
import random
from datetime import timedelta
from flask import Flask, render_template, jsonify, Response,request, redirect
import requests
from io import BytesIO
 


## PROXY SETTINGS ========
# If you are behind a proxy then set it here
# proxies = {'http': 'http://myproxy:8080', 'https': 'http://myproxy:8080'}
# If the proxy requires authentication use the following:
# proxies = {'http': 'http://user:password@myproxy:8080', 'https': 'http://user:password@myproxy:8080'}
proxies = ""
##===================

## SSL VERIFICATION SETTINGS =
SSL_verify = True
##===================
def datetime_converter(content):
    """
    :param content
    :returns string content
    """
    # convert datetime data type to string
    if isinstance(content, datetime.datetime):
       return content.__str__()
                   
def data_sender():
        
    """
    :param  
    :returns content , msg
    """
    while True: 
    
        # calculate the duration in second before the next request
        now = datetime.datetime.now()
        sec_left = (now - MyVariables.last_req).seconds
        next_req = abs(MyVariables.interval - sec_left) 
 
        
        # send content to "list" event listener 
        json_content = json.dumps(MyVariables.content,default = datetime_converter)
        yield f"event:list\n"
        yield f"data:{json_content}\n\n" 
        
        # send msg to "msg" event listener 
        json_msg = json.dumps(MyVariables.msg)   
        yield f"event: msg\n"
        yield f"data:{json_msg}\n\n" 
 
        time.sleep(next_req +10)
 
         
def checkMetadate(metadate, status, msg, content, metaFile):
	""""
	:param  metadate, status, msg, content current values and downloaded metaFile
	:returns updated metadate, status, msg, content

	"""
	metaFile = metaFile.decode("utf-8")
	modifiedDate = metaFile.split('\n', 1)[0].split(':', 1)[1].split(':', 1)[0]
	modifiedDate = datetime.datetime.strptime(modifiedDate, '%Y-%m-%dT%H')

	if (modifiedDate > metadate):
		metadate = modifiedDate
		status = 'fine'
		msg = ''

		try:
			# Request the latest CVE list from nvd.nist.gov
			buffer = requests.get("https://nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-modified.json.gz" ,proxies=proxies, verify=SSL_verify)
			
			# Decompress the downloaded file 
			json_bytes = gzip.GzipFile(fileobj=BytesIO(buffer.content)).read()
			status, msg, content = get_content(status, msg, content, json_bytes)
 

		except Exception as e:
			print("ERROR: " + str(e))
			status = 'error'
			msg = "Downloading of the CVE file has failed!"

	# No new data
	else:
		status = 'fine'
		msg = ''
		content, status, msg = refilter_content(content, status, msg)
 

	return metadate, status, msg, content

def highlight_keywords(keyword_processor):
    """
    :param keyword_processor
    :returns 
	""" 
	# add and highlight keywords 
    filepath = 'keywords.txt'	
    with open(filepath) as fp:
	        line = fp.readlines()
	        for word in line:
	            # .strip() to remove leading and trailing whitespaces from the word 
	            keyword_processor.add_keyword(word.strip(), "<span style=\"background-color: #FFFF00;\">"+ word +"</span> ")
	                 	                 
	                 
def get_content(status, msg, content, json_bytes):
	""""
	 :param  metadate, status, msg, content current values and downloaded json_bytes file which contains cve data
	 :returns updated metadate, status, msg, content
	 """

	cve_list = []
	# get UTC current time
	date = datetime.datetime.utcnow()
	json_str = json_bytes.decode('utf-8')
	data = json.loads(json_str)
	extracted_list = {}
	score = 1
	stored_list = data['CVE_Items']
	
	keyword_processor = flashtext.KeywordProcessor()
	highlight_keywords(keyword_processor)


		
     
	#   collect cve info where is last update date < 24 hour & score> 
	for index in range(len(stored_list)):
		if 'baseMetricV3' in stored_list[index]['impact']:
			lastMod_object = datetime.datetime.strptime(stored_list[index]['lastModifiedDate'],'%Y-%m-%dT%H:%MZ')
			publish_object = datetime.datetime.strptime(stored_list[index]['publishedDate'],	'%Y-%m-%dT%H:%MZ')
			# check score based on cvss version 3
			if (stored_list[index]['impact']['baseMetricV3']['cvssV3'][
				'baseScore'] >= score and (
					date - lastMod_object <= timedelta(hours=24) or date - publish_object <= timedelta(hours=24))):
				extracted_list = {'URL':('https://nvd.nist.gov/vuln/detail/'+stored_list[index]['cve']['CVE_data_meta']['ID']),
					'ID': stored_list[index]['cve']['CVE_data_meta']['ID'],
					'Description': keyword_processor.replace_keywords(stored_list[index]['cve']['description']['description_data'][0]['value']),
					'Score': stored_list[index]['impact']['baseMetricV3']['cvssV3']['baseScore'],
					'Last_Updated': (
						datetime.datetime.strptime(str(lastMod_object + timedelta(seconds=3600 * 3)), '%Y-%m-%d %H:%M:%S')),
				}
 
				cve_list.append(extracted_list)
	            
	            
	            
				

	# check cve score version 2
	else:
		if 'baseMetricV2' in stored_list[index]['impact']:
			lastMod_object = datetime.datetime.strptime(stored_list[index]['lastModifiedDate'],'%Y-%m-%dT%H:%MZ')
			publish_object = datetime.datetime.strptime(stored_list[index]['publishedDate'],'%Y-%m-%dT%H:%MZ')
			if (stored_list[index]['impact']['baseMetricV2']['cvssV2']['baseScore'] >= score and (
					date - lastMod_object <= timedelta(hours=24) or date - publish_object <= timedelta(hours=24))):
				extracted_list = {'URL': ('https://nvd.nist.gov/vuln/detail/'+stored_list[index]['cve']['CVE_data_meta']['ID']),
					'ID': stored_list[index]['cve']['CVE_data_meta']['ID'],
					'Description': keyword_processor.replace_keywords(stored_list[index]['cve']['description']['description_data'][0]['value']),
					'Score': stored_list[index]['impact']['baseMetricV2']['cvssV2']['baseScore'],'Last_Updated': (
						datetime.datetime.strptime(str(lastMod_object + timedelta(seconds=3600 * 3)), '%Y-%m-%d %H:%M:%S')),
				}
 
				cve_list.append(extracted_list)

	if len(cve_list) > 0:  # sort new content
		content, status, msg = sort_content(cve_list, content, status, msg)

	else:  # no new content ->filter current content
		content, status, msg = refilter_content(content, status, msg)

	return status, msg, content


def sort_content(cve_list, content, status, msg):
	# Sort by recent updated cve ,if two IDs have the same hours then put the highest score first
	if len(cve_list) > 0:
		sort = sorted(cve_list, key=lambda x: (x['Last_Updated'], x['Score']), reverse=True)
		content = sort
		msg = ''
	elif len(cve_list) <= 0:
		msg = 'No new data since last 24 hours'

	return content, status, msg


def refilter_content(content, status, msg):
	"""
	 re-filter current content to remove any old data(24h since it last modified)
	"""
	# get local date&time
	date = datetime.datetime.now()
	list2 = []


	if len(content) > 0:
		for dic in content:
			for key in dic:
				if key == 'Last_Updated':

					if date - dic[key] < timedelta(days=1, hours=24):
						list2.append(dic)
       
    
	content, status, msg = sort_content(list2, content, status, msg)
 

	return content, status, msg


def main():
	try:
		url = 'https://nvd.nist.gov/feeds/json/cve/1.0/nvdcve-1.0-modified.meta'
		buffer = requests.get(url, proxies=proxies, verify=SSL_verify)
		buffer.raise_for_status()
		metaFile = buffer.content
		MyVariables.interval = 1800 # check meta data every 30 minutes (30*60seconds=1800 seconds)
		threading.Timer(MyVariables.interval, main).start()	 
		MyVariables.last_req = datetime.datetime.now()

		MyVariables.metadate, MyVariables.status, MyVariables.msg, MyVariables.content = checkMetadate(MyVariables.metadate, MyVariables.status, MyVariables.msg, MyVariables.content, metaFile)
        

	
	# 	invalid HTTP response
	except requests.exceptions.HTTPError as errh:
		
		MyVariables.status = 'error'		  
		# check connection after 5 mins
		MyVariables.interval = 60 * 5
		threading.Timer(MyVariables.interval, main).start()
		MyVariables.last_req = datetime.datetime.now()
		if "Error 404" in MyVariables.msg:

			MyVariables.msg = "Nist Page Not Found"
		else:
		
		    MyVariables.msg = "Http Error:" +str(errh)
	
	 # 	network problems
	except requests.exceptions.ConnectionError as errc:
		MyVariables.status = 'error'
		MyVariables.msg = "Internet Connection Problem"
			  
		# check connection after 5 mins
		MyVariables.interval = 60 * 5
		threading.Timer(MyVariables.interval, main).start()
		MyVariables.last_req = datetime.datetime.now()
	
	# request exceeds the configured number of maximum redirections
	except requests.exceptions.Timeout as errt:
		MyVariables.status = 'error'
		MyVariables.msg =  "Request Timeout Error"
			  
		# check connection after 5 mins
		MyVariables.interval = 60 * 5
		threading.Timer(MyVariables.interval, main).start()
		MyVariables.last_req = datetime.datetime.now()
    
    
    # All other exceptions
	except requests.exceptions.RequestException as err:
		MyVariables.status = 'error'
		MyVariables.msg =   "Error:"+str(err)
			  
		# check connection after 5 mins
		MyVariables.interval = 60 * 5
		threading.Timer(MyVariables.interval, main).start()
		MyVariables.last_req = datetime.datetime.now()
 
class MyVariables:
	"""
	this class created to initiate and keep metadate, content , status, msg,interval,last_req current values

	"""
	metadate = datetime.datetime.strptime('2019-07-04T01', '%Y-%m-%dT%H')
	content = ''
	status = 'error'
	msg = ''
	interval = 60 * 5
	last_req = datetime.datetime.now()
 


main()
 

# app section
app = Flask(__name__)


# return view.html to each client first request
@app.route('/')
def view_page():
 return render_template('view.html')
 
@app.route('/data', methods=['GET'])
def data():
    return Response(data_sender(), mimetype='text/event-stream')



if __name__ == '__main__':
	app.run(threaded = True)
